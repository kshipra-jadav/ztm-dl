{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food 101 Big Part 1 - TensorFlow Course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting The Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-16 19:49:18--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10246 (10K) [text/plain]\n",
      "Saving to: ‘helper_functions.py’\n",
      "\n",
      "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-02-16 19:49:18 (22.1 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TensorFlow Datasets (TFDS) To Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract_reasoning',\n",
       " 'accentdb',\n",
       " 'aeslc',\n",
       " 'aflw2k3d',\n",
       " 'ag_news_subset',\n",
       " 'ai2_arc',\n",
       " 'ai2_arc_with_ir',\n",
       " 'amazon_us_reviews',\n",
       " 'anli',\n",
       " 'answer_equivalence']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listing all available datasets \n",
    "tfds.list_builders()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'food101' in tfds.list_builders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 4.65 GiB (download: 4.65 GiB, generated: Unknown size, total: 4.65 GiB) to /home/20bt04013/tensorflow_datasets/food101/2.0.0...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:03<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:04<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:05<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:06<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:07<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:08<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:09<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:11<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:13<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:14<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:16<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:18<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:20<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:22<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:25<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:27<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:29<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:30<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:32<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:33<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:33<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:34<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:35<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:37<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:39<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:41<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:43<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:44<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:45<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:46<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:46<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:47<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:47<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:48<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:48<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:49<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:49<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:49<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:50<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:50<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:51<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:52<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:52<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:54<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:56<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:58<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:02<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:03<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:05<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:05<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:06<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:07<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:07<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:08<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:08<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:09<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:09<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:09<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:10<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:10<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:11<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:11<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:12<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:13<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:14<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:14<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:16<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:17<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:18<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:20<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:21<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:22<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:23<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:24<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:24<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:25<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:26<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:26<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:27<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:27<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:28<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:29<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:30<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:30<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:31<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:32<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:33<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:33<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:34<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:35<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:36<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:36<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:37<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:38<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:39<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:39<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:40<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:41<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:41<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:42<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:42<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:43<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:44<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:44<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:45<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:46<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:46<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:47<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:48<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:49<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:49<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:50<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:51<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:52<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:53<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:54<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:55<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:55<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:57<?, ? url/s]\n",
      "Extraction completed...: 0 file [01:57, ? file/s]\n",
      "Dl Size...:   3%|▎         | 120/4764 [01:57<1:15:30,  1.03 MiB/s]\n",
      "Dl Completed...:   0%|          | 0/1 [01:57<?, ? url/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Load In The Food101 Dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m (train_data, test_data), ds_info \u001b[39m=\u001b[39m tfds\u001b[39m.\u001b[39;49mload(name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfood101\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m                                              split\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mvalidation\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      4\u001b[0m                                              shuffle_files\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \n\u001b[1;32m      5\u001b[0m                                              as_supervised\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m# download with labels and data gets returns in tuple format (data, label)\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m                                              with_info\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m \u001b[39m# download meta-data also\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m                                              )\n",
      "File \u001b[0;32m~/.conda/envs/tf_course/lib/python3.11/site-packages/tensorflow_datasets/core/logging/__init__.py:168\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[0;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_call()\n\u001b[1;32m    167\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m   \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m   metadata\u001b[39m.\u001b[39mmark_error()\n",
      "File \u001b[0;32m~/.conda/envs/tf_course/lib/python3.11/site-packages/tensorflow_datasets/core/load.py:649\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Loads the named dataset into a `tf.data.Dataset`.\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \n\u001b[1;32m    532\u001b[0m \u001b[39m`tfds.load` is a convenience method that:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[39m    Split-specific information is available in `ds_info.splits`.\u001b[39;00m\n\u001b[1;32m    642\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    643\u001b[0m dbuilder \u001b[39m=\u001b[39m _fetch_builder(\n\u001b[1;32m    644\u001b[0m     name,\n\u001b[1;32m    645\u001b[0m     data_dir,\n\u001b[1;32m    646\u001b[0m     builder_kwargs,\n\u001b[1;32m    647\u001b[0m     try_gcs,\n\u001b[1;32m    648\u001b[0m )\n\u001b[0;32m--> 649\u001b[0m _download_and_prepare_builder(dbuilder, download, download_and_prepare_kwargs)\n\u001b[1;32m    651\u001b[0m \u001b[39mif\u001b[39;00m as_dataset_kwargs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    652\u001b[0m   as_dataset_kwargs \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/.conda/envs/tf_course/lib/python3.11/site-packages/tensorflow_datasets/core/load.py:508\u001b[0m, in \u001b[0;36m_download_and_prepare_builder\u001b[0;34m(dbuilder, download, download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[39mif\u001b[39;00m download:\n\u001b[1;32m    507\u001b[0m   download_and_prepare_kwargs \u001b[39m=\u001b[39m download_and_prepare_kwargs \u001b[39mor\u001b[39;00m {}\n\u001b[0;32m--> 508\u001b[0m   dbuilder\u001b[39m.\u001b[39;49mdownload_and_prepare(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdownload_and_prepare_kwargs)\n",
      "File \u001b[0;32m~/.conda/envs/tf_course/lib/python3.11/site-packages/tensorflow_datasets/core/logging/__init__.py:168\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[0;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_call()\n\u001b[1;32m    167\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m   \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m   metadata\u001b[39m.\u001b[39mmark_error()\n",
      "File \u001b[0;32m~/.conda/envs/tf_course/lib/python3.11/site-packages/tensorflow_datasets/core/dataset_builder.py:691\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, download_dir, download_config, file_format)\u001b[0m\n\u001b[1;32m    689\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mread_from_directory(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_dir)\n\u001b[1;32m    690\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 691\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[1;32m    692\u001b[0m       dl_manager\u001b[39m=\u001b[39;49mdl_manager,\n\u001b[1;32m    693\u001b[0m       download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m    694\u001b[0m   )\n\u001b[1;32m    696\u001b[0m   \u001b[39m# NOTE: If modifying the lines below to put additional information in\u001b[39;00m\n\u001b[1;32m    697\u001b[0m   \u001b[39m# DatasetInfo, you'll likely also want to update\u001b[39;00m\n\u001b[1;32m    698\u001b[0m   \u001b[39m# DatasetInfo.read_from_directory to possibly restore these attributes\u001b[39;00m\n\u001b[1;32m    699\u001b[0m   \u001b[39m# when reading from package data.\u001b[39;00m\n\u001b[1;32m    700\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdownload_size \u001b[39m=\u001b[39m dl_manager\u001b[39m.\u001b[39mdownloaded_size\n",
      "File \u001b[0;32m~/.conda/envs/tf_course/lib/python3.11/site-packages/tensorflow_datasets/core/dataset_builder.py:1547\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, download_config)\u001b[0m\n\u001b[1;32m   1545\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1546\u001b[0m   optional_pipeline_kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m-> 1547\u001b[0m split_generators \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_split_generators(  \u001b[39m# pylint: disable=unexpected-keyword-arg\u001b[39;49;00m\n\u001b[1;32m   1548\u001b[0m     dl_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptional_pipeline_kwargs\n\u001b[1;32m   1549\u001b[0m )\n\u001b[1;32m   1550\u001b[0m \u001b[39m# TODO(tfds): Could be removed once all datasets are migrated.\u001b[39;00m\n\u001b[1;32m   1551\u001b[0m \u001b[39m# https://github.com/tensorflow/datasets/issues/2537\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39m# Legacy mode (eventually convert list[SplitGeneratorLegacy] -> dict)\u001b[39;00m\n\u001b[1;32m   1553\u001b[0m split_generators \u001b[39m=\u001b[39m split_builder\u001b[39m.\u001b[39mnormalize_legacy_split_generators(\n\u001b[1;32m   1554\u001b[0m     split_generators\u001b[39m=\u001b[39msplit_generators,\n\u001b[1;32m   1555\u001b[0m     generator_fn\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_examples,\n\u001b[1;32m   1556\u001b[0m     is_beam\u001b[39m=\u001b[39m\u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, BeamBasedBuilder),\n\u001b[1;32m   1557\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/tf_course/lib/python3.11/site-packages/tensorflow_datasets/image_classification/food101.py:81\u001b[0m, in \u001b[0;36mFood101._split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_split_generators\u001b[39m(\u001b[39mself\u001b[39m, dl_manager):\n\u001b[1;32m     79\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Define Splits.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m   dl_path \u001b[39m=\u001b[39m dl_manager\u001b[39m.\u001b[39;49mdownload_and_extract(_BASE_URL)\n\u001b[1;32m     82\u001b[0m   meta_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dl_path, \u001b[39m\"\u001b[39m\u001b[39mfood-101\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmeta\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     83\u001b[0m   image_dir_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dl_path, \u001b[39m\"\u001b[39m\u001b[39mfood-101\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/tf_course/lib/python3.11/site-packages/tensorflow_datasets/core/download/download_manager.py:688\u001b[0m, in \u001b[0;36mDownloadManager.download_and_extract\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_downloader\u001b[39m.\u001b[39mtqdm():\n\u001b[1;32m    687\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extractor\u001b[39m.\u001b[39mtqdm():\n\u001b[0;32m--> 688\u001b[0m     \u001b[39mreturn\u001b[39;00m _map_promise(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_extract, url_or_urls)\n",
      "File \u001b[0;32m~/.conda/envs/tf_course/lib/python3.11/site-packages/tensorflow_datasets/core/download/download_manager.py:831\u001b[0m, in \u001b[0;36m_map_promise\u001b[0;34m(map_fn, all_inputs)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Map the function into each element and resolve the promise.\"\"\"\u001b[39;00m\n\u001b[1;32m    828\u001b[0m all_promises \u001b[39m=\u001b[39m tree_utils\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m    829\u001b[0m     map_fn, all_inputs\n\u001b[1;32m    830\u001b[0m )  \u001b[39m# Apply the function\u001b[39;00m\n\u001b[0;32m--> 831\u001b[0m res \u001b[39m=\u001b[39m tree_utils\u001b[39m.\u001b[39;49mmap_structure(\n\u001b[1;32m    832\u001b[0m     \u001b[39mlambda\u001b[39;49;00m p: p\u001b[39m.\u001b[39;49mget(), all_promises\n\u001b[1;32m    833\u001b[0m )  \u001b[39m# Wait promises\u001b[39;00m\n\u001b[1;32m    834\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/.conda/envs/tf_course/lib/python3.11/site-packages/tree/__init__.py:435\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structures, **kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39mfor\u001b[39;00m other \u001b[39min\u001b[39;00m structures[\u001b[39m1\u001b[39m:]:\n\u001b[1;32m    433\u001b[0m   assert_same_structure(structures[\u001b[39m0\u001b[39m], other, check_types\u001b[39m=\u001b[39mcheck_types)\n\u001b[1;32m    434\u001b[0m \u001b[39mreturn\u001b[39;00m unflatten_as(structures[\u001b[39m0\u001b[39m],\n\u001b[0;32m--> 435\u001b[0m                     [func(\u001b[39m*\u001b[39;49margs) \u001b[39mfor\u001b[39;49;00m args \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(flatten, structures))])\n",
      "File \u001b[0;32m~/.conda/envs/tf_course/lib/python3.11/site-packages/tree/__init__.py:435\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39mfor\u001b[39;00m other \u001b[39min\u001b[39;00m structures[\u001b[39m1\u001b[39m:]:\n\u001b[1;32m    433\u001b[0m   assert_same_structure(structures[\u001b[39m0\u001b[39m], other, check_types\u001b[39m=\u001b[39mcheck_types)\n\u001b[1;32m    434\u001b[0m \u001b[39mreturn\u001b[39;00m unflatten_as(structures[\u001b[39m0\u001b[39m],\n\u001b[0;32m--> 435\u001b[0m                     [func(\u001b[39m*\u001b[39;49margs) \u001b[39mfor\u001b[39;00m args \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(flatten, structures))])\n",
      "File \u001b[0;32m~/.conda/envs/tf_course/lib/python3.11/site-packages/tensorflow_datasets/core/download/download_manager.py:832\u001b[0m, in \u001b[0;36m_map_promise.<locals>.<lambda>\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Map the function into each element and resolve the promise.\"\"\"\u001b[39;00m\n\u001b[1;32m    828\u001b[0m all_promises \u001b[39m=\u001b[39m tree_utils\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m    829\u001b[0m     map_fn, all_inputs\n\u001b[1;32m    830\u001b[0m )  \u001b[39m# Apply the function\u001b[39;00m\n\u001b[1;32m    831\u001b[0m res \u001b[39m=\u001b[39m tree_utils\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m--> 832\u001b[0m     \u001b[39mlambda\u001b[39;00m p: p\u001b[39m.\u001b[39;49mget(), all_promises\n\u001b[1;32m    833\u001b[0m )  \u001b[39m# Wait promises\u001b[39;00m\n\u001b[1;32m    834\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/.conda/envs/tf_course/lib/python3.11/site-packages/promise/promise.py:511\u001b[0m, in \u001b[0;36mPromise.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    509\u001b[0m     \u001b[39m# type: (Optional[float]) -> T\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_target()\n\u001b[0;32m--> 511\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait(timeout \u001b[39mor\u001b[39;49;00m DEFAULT_TIMEOUT)\n\u001b[1;32m    512\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_target_settled_value(_raise\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/tf_course/lib/python3.11/site-packages/promise/promise.py:506\u001b[0m, in \u001b[0;36mPromise._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    505\u001b[0m     \u001b[39m# type: (Optional[float]) -> None\u001b[39;00m\n\u001b[0;32m--> 506\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(\u001b[39mself\u001b[39;49m, timeout)\n",
      "File \u001b[0;32m~/.conda/envs/tf_course/lib/python3.11/site-packages/promise/promise.py:502\u001b[0m, in \u001b[0;36mPromise.wait\u001b[0;34m(cls, promise, timeout)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    500\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mcls\u001b[39m, promise, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    501\u001b[0m     \u001b[39m# type: (Promise, Optional[float]) -> None\u001b[39;00m\n\u001b[0;32m--> 502\u001b[0m     async_instance\u001b[39m.\u001b[39;49mwait(promise, timeout)\n",
      "File \u001b[0;32m~/.conda/envs/tf_course/lib/python3.11/site-packages/promise/async_.py:117\u001b[0m, in \u001b[0;36mAsync.wait\u001b[0;34m(self, promise, timeout)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m promise\u001b[39m.\u001b[39mis_pending:\n\u001b[1;32m    114\u001b[0m         \u001b[39m# We return if the promise is already\u001b[39;00m\n\u001b[1;32m    115\u001b[0m         \u001b[39m# fulfilled or rejected\u001b[39;00m\n\u001b[1;32m    116\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m target\u001b[39m.\u001b[39;49mscheduler\u001b[39m.\u001b[39;49mwait(target, timeout)\n",
      "File \u001b[0;32m~/.conda/envs/tf_course/lib/python3.11/site-packages/promise/schedulers/immediate.py:25\u001b[0m, in \u001b[0;36mImmediateScheduler.wait\u001b[0;34m(self, promise, timeout)\u001b[0m\n\u001b[1;32m     22\u001b[0m     e\u001b[39m.\u001b[39mset()\n\u001b[1;32m     24\u001b[0m promise\u001b[39m.\u001b[39m_then(on_resolve_or_reject, on_resolve_or_reject)\n\u001b[0;32m---> 25\u001b[0m waited \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m     26\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m waited:\n\u001b[1;32m     27\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTimeout\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/tf_course/lib/python3.11/threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    628\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 629\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    630\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/.conda/envs/tf_course/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    328\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load In The Food101 Dataset\n",
    "(train_data, test_data), ds_info = tfds.load(name=\"food101\",\n",
    "                                             split=['train', 'validation'],\n",
    "                                             shuffle_files=True, \n",
    "                                             as_supervised=True, # download with labels and data gets returns in tuple format (data, label)\n",
    "                                             with_info=True # download meta-data also\n",
    "                                             )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
